# Improved_DeepLabV3-_Model
 The semantic segmentation model of suburban road lane detection adopts the modification of DeepLabV3+ original architecture.
### Improved enhanced DeepLabV3Plus network model
Improved DeepLabV3+ model source code and self-built dataset Sublane

### Desired environment
Torch==2.2.2  
CUDA==11.8  
Python==3.18   

### File download

The SubLane dataset is available for download at Thunderbolt:  
https://pan.xunlei.com/s/VOBiDBpldbtFoH7C3J3BtTrDA1

The Baidu web disk of VOC expansion data set is as follows:  
https://pan.baidu.com/s/1vkk3lMheUm6IjTXznlg7Ng

### File comments

1.datasets folder before file into the original image file and json file.  
2.Run josn_to_datasets file to generate semantically segmented images and store them in datasets\SegmentationClass.  
3.img folder to store test images. The img_out folder contains the superposed image of the actual image output from the test image and the segmented image.  
5.logs store the training and validation loss change images, miou change images, and the weights under each training stage epoch.  
6.miou_out stores test result graphs of miou, mpa, precision, recall and confusion matrix files.  
7.model_data is a pre-trained weights file that you can use to train your own dataset.  
8. The backbone network, DySample and CBAM modules used in this paper are placed in the nets folder  
9.VOCdevkit is in 2007 format, so you need to put the JPEGImages and SegmentationClass file contents from datasets in a folder. VOCdevkit\ImageSets\Segmentation contains the training and validation.txt files.  

### Program
#### Training
1. Collect your own dataset and annotate all the datasets
(The dataset is in.jpg format and the tags are in.json format, all in one folder.)
Transform the dataset using step1_seg_image_gen.py
(The original.JPG image is stored in JPEGImages and the segmented.png format image is stored in SegmentationClass)
3. Combine JPEGImages and SegmentationClass in VOCdevkit/VOC2007
Replace with JPEGImages and SegmentationClass in datasets (copy and replace)
4, use step2_reset_tra_and_val.py to randomly divide the data set into a certain proportion of.txt
The split training set and training validation set are stored in train.txt, trainval.txt, and val.txt of Segmentation
(Assuming 1000 data sets and 8:2 training validation, then trainval=1000, train=800, val=200)
In train.py, select the backbone model you want to use and the downsampling factor.
The backbone model provided in this paper is mobilenet. The downsampling factor can be chosen between 8 and 16.
It is important to note that the pre-trained model needs to correspond to the backbone model
Change num_classes in train.py to +1, and run train.py to start training

#### Predict
The steps of prediction are relatively simple, refer to the program notes for details
##### get_miou.py  
Metrics evaluation should pay attention to the following points:
1. The graph generated by this file is grayscale. Because the value is relatively small, there is no display effect according to the PNG form, so it is normal to see the graph that is nearly all black.
2. This file calculates the miou of the validation set. Currently, the library uses the test set as the validation set, and does not separate the test set
##### predict.py  
Single image prediction. If you want to modify the prediction process, such as saving the image, intercepting the object, etc., you can look at the detailed comments first
Video detection, you can call the camera or video for detection, see the details of the notes.
To test fps, the image used is xxx.jpg in img, see the comments for details.
#### Notes
1. Carefully check whether your format meets the requirements before training. The library requires the data set format to be VOC format.
The content that needs to be prepared is the input image and the label. The input image is a.JPG image, without fixed size, and the resize will be automatically performed before passing it to the training.
2. If the format is wrong, refer to: https://github.com/bubbliiiing/segmentation-format-fix
The trained weights file is saved in the logs folder. Each training Epoch contains a number of training steps, and gradient descent is performed once for each training Step.
4. The training is divided into two phases, which are the freezing phase and the thawing phase. The freezing phase is set to meet the training needs of insufficient machine performance.

### Reference
https://github.com/ggyyzm/pytorch_segmentation  
https://github.com/bonlime/keras-deeplab-v3-plus  
https://github.com/bubbliiiing/deeplabv3-plus-pytorch
